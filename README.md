# ParsParaphraser

This paper investigates the problem of sentence paraphrasing for the Persian language, which is a low-resource and morphologically rich language. The paper proposes to use the Text-To-Text Transfer Transformer (T5) model, which is a pre-trained encoder-decoder model that can handle various natural language processing tasks. The paper fine-tunes the T5 model on a newly created Persian paraphrase dataset and evaluates its performance on two metrics: BLEU and ROUGE. The paper also compares the T5 model with two baselines: a rule-based approach and a statistical machine translation approach. The paper reports that the T5 model outperforms the baselines on both metrics and generates fluent and diverse paraphrases for Persian sentences.
