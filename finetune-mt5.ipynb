{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009677,
     "end_time": "2022-08-28T15:45:31.825002",
     "exception": false,
     "start_time": "2022-08-28T15:45:31.815325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:45:31.847693Z",
     "iopub.status.busy": "2022-08-28T15:45:31.846920Z",
     "iopub.status.idle": "2022-08-28T15:45:51.282922Z",
     "shell.execute_reply": "2022-08-28T15:45:51.282319Z"
    },
    "papermill": {
     "duration": 19.449423,
     "end_time": "2022-08-28T15:45:51.283048",
     "exception": false,
     "start_time": "2022-08-28T15:45:31.833625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.7/site-packages (1.0.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.18.2)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (5.3.1)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2.4.0)\r\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.6.0)\r\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.8.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.18.5)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.45.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.23.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.14.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.11.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.34.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.2.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.1)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.33.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.7.0)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2020.11.8)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (3.0.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.0.0rc1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading transformers-4.0.0rc1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 830 kB/s eta 0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |▌                               | 20 kB 349 kB/s eta 0:00:04\r",
      "\u001b[K     |▊                               | 30 kB 522 kB/s eta 0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█                               | 40 kB 202 kB/s eta 0:00:07\r",
      "\u001b[K     |█▏                              | 51 kB 223 kB/s eta 0:00:06\r",
      "\u001b[K     |█▌                              | 61 kB 268 kB/s eta 0:00:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█▊                              | 71 kB 281 kB/s eta 0:00:05\r",
      "\u001b[K     |██                              | 81 kB 296 kB/s eta 0:00:05\r",
      "\u001b[K     |██▏                             | 92 kB 333 kB/s eta 0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |██▍                             | 102 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |██▊                             | 112 kB 260 kB/s eta 0:00:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███                             | 122 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |███▏                            | 133 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |███▍                            | 143 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |███▋                            | 153 kB 260 kB/s eta 0:00:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███▉                            | 163 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |████▏                           | 174 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |████▍                           | 184 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |████▋                           | 194 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |████▉                           | 204 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |█████                           | 215 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |█████▍                          | 225 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |█████▋                          | 235 kB 260 kB/s eta 0:00:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█████▉                          | 245 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |██████                          | 256 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |██████▎                         | 266 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |██████▋                         | 276 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |██████▉                         | 286 kB 260 kB/s eta 0:00:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███████                         | 296 kB 260 kB/s eta 0:00:05\r",
      "\u001b[K     |███████▎                        | 307 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████▌                        | 317 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████▊                        | 327 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████                        | 337 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████▎                       | 348 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████▌                       | 358 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████▊                       | 368 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |█████████                       | 378 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |█████████▎                      | 389 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |█████████▌                      | 399 kB 260 kB/s eta 0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█████████▊                      | 409 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |██████████                      | 419 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |██████████▏                     | 430 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |██████████▍                     | 440 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |██████████▊                     | 450 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████████                     | 460 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████████▏                    | 471 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████████▍                    | 481 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |███████████▋                    | 491 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████████                    | 501 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████████▏                   | 512 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████████▍                   | 522 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |████████████▋                   | 532 kB 260 kB/s eta 0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████████████▉                   | 542 kB 260 kB/s eta 0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█████████████▏                  | 552 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |█████████████▍                  | 563 kB 260 kB/s eta 0:00:04\r",
      "\u001b[K     |█████████████▋                  | 573 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████▉                  | 583 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████                  | 593 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████▎                 | 604 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████▋                 | 614 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████▉                 | 624 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████                 | 634 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████▎                | 645 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████▌                | 655 kB 260 kB/s eta 0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███████████████▉                | 665 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████                | 675 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████▎               | 686 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████▌               | 696 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████▊               | 706 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████               | 716 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████▎              | 727 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████▌              | 737 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████▊              | 747 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 757 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▏             | 768 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▌             | 778 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▊             | 788 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 798 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▏            | 808 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▍            | 819 kB 260 kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▊            | 829 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████            | 839 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████▏           | 849 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████▍           | 860 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████▋           | 870 kB 260 kB/s eta 0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████████████████████▉           | 880 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████▏          | 890 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████▍          | 901 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████▋          | 911 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████▉          | 921 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████          | 931 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████▍         | 942 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████▋         | 952 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████▉         | 962 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████         | 972 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████▎        | 983 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████▋        | 993 kB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████▉        | 1.0 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████        | 1.0 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████▎       | 1.0 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████▌       | 1.0 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████▊       | 1.0 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████       | 1.1 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████▎      | 1.1 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████▌      | 1.1 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████▊      | 1.1 MB 260 kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████      | 1.1 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.1 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.1 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.1 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.1 MB 260 kB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███████████████████████████▏    | 1.1 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.2 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.3 MB 260 kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.3 MB 260 kB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████████████████████████████████| 1.3 MB 260 kB/s \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (2.23.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (4.45.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (2020.4.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.9.4\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\r\n",
      "\u001b[?25l\r",
      "\u001b[K     |▏                               | 10 kB 30.7 MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 20 kB 19.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 30 kB 25.3 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 40 kB 21.0 MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 51 kB 13.7 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 61 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 71 kB 15.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 81 kB 16.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 92 kB 16.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 102 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 112 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 122 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 133 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 143 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 153 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 163 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 174 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 184 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 194 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 204 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 215 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 225 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 235 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 245 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 256 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 266 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 276 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 286 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 296 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 307 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 317 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 327 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 337 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 348 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 358 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 368 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 378 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 389 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 399 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 409 kB 15.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████▋                           | 419 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 430 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 440 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 450 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 460 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 471 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 481 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 491 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 501 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 512 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 522 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 532 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 542 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 552 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 563 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 573 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 583 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 593 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 604 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 614 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 624 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 634 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 645 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 655 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 665 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 675 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 686 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 696 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 706 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 716 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 727 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 737 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 747 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 757 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 768 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 778 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 788 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 798 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 808 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 819 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 829 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 839 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 849 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 860 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 870 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 880 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 890 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 901 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 911 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 921 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 931 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 942 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 952 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 962 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 972 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 983 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 993 kB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 1.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 1.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 1.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 1.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 1.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 1.1 MB 15.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████████████▎                   | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 1.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 1.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 1.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 1.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 1.8 MB 15.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███████████████████▎            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 1.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 2.0 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 2.1 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 2.2 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 2.3 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 2.4 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.5 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 2.6 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 2.7 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 2.8 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 2.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 2.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 2.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 2.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 2.9 MB 15.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.9 MB 15.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |████████████████████████████████| 2.9 MB 15.8 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (20.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (1.18.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (3.0.10)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (0.0.43)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (2.9)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (2020.11.8)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (3.0.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.0.0rc1) (1.14.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.0.0rc1) (2.4.7)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.0.0rc1) (7.1.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.0.0rc1) (0.14.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.9.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling tokenizers-0.9.2:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled tokenizers-0.9.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: transformers 3.4.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling transformers-3.4.0:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled transformers-3.4.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\r\n",
      "\r\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\r\n",
      "\r\n",
      "allennlp 1.2.1 requires transformers<3.5,>=3.1, but you'll have transformers 4.0.0rc1 which is incompatible.\u001b[0m\r\n",
      "Successfully installed tokenizers-0.9.4 transformers-4.0.0rc1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install transformers==4.0.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-28T15:45:51.333059Z",
     "iopub.status.busy": "2022-08-28T15:45:51.332117Z",
     "iopub.status.idle": "2022-08-28T15:45:59.977635Z",
     "shell.execute_reply": "2022-08-28T15:45:59.976104Z"
    },
    "papermill": {
     "duration": 8.672575,
     "end_time": "2022-08-28T15:45:59.977754",
     "exception": false,
     "start_time": "2022-08-28T15:45:51.305179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02,
     "end_time": "2022-08-28T15:46:00.017633",
     "exception": false,
     "start_time": "2022-08-28T15:45:59.997633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:00.068356Z",
     "iopub.status.busy": "2022-08-28T15:46:00.061194Z",
     "iopub.status.idle": "2022-08-28T15:46:02.954061Z",
     "shell.execute_reply": "2022-08-28T15:46:02.953110Z"
    },
    "papermill": {
     "duration": 2.916839,
     "end_time": "2022-08-28T15:46:02.954222",
     "exception": false,
     "start_time": "2022-08-28T15:46:00.037383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "#wandb.login('3aa5adb8223166fea653d0941937427288afdf37')\n",
    "!wandb login 3aa5adb8223166fea653d0941937427288afdf37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022677,
     "end_time": "2022-08-28T15:46:02.999843",
     "exception": false,
     "start_time": "2022-08-28T15:46:02.977166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.053497Z",
     "iopub.status.busy": "2022-08-28T15:46:03.052597Z",
     "iopub.status.idle": "2022-08-28T15:46:03.058110Z",
     "shell.execute_reply": "2022-08-28T15:46:03.057688Z"
    },
    "papermill": {
     "duration": 0.035484,
     "end_time": "2022-08-28T15:46:03.058228",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.022744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.138100Z",
     "iopub.status.busy": "2022-08-28T15:46:03.136139Z",
     "iopub.status.idle": "2022-08-28T15:46:03.138819Z",
     "shell.execute_reply": "2022-08-28T15:46:03.139257Z"
    },
    "papermill": {
     "duration": 0.057372,
     "end_time": "2022-08-28T15:46:03.139364",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.081992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparams   = hparams\n",
    "        self.model     = MT5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "        wandb.init(project=\"transformers_ParsParaphraser\")\n",
    "        wandb.watch(self.model, log=\"all\")\n",
    "\n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        labels = batch[\"target_ids\"]\n",
    "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        wandb.log({\"train_loss\": loss})\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "        wandb.log({\"avg_train_loss\": avg_train_loss})\n",
    "        values =  {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "        self.log_dict(values)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"val_loss\",loss)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_loss  = 0\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "        wandb.log({\"val_loss\": avg_loss})\n",
    "        values =  {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "        self.log_dict(values)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    def optimizer_step(self,epoch, batch_idx, optimizer, optimizer_idx,optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n",
    "        if self.trainer.use_tpu:\n",
    "            xm.optimizer_step(optimizer)\n",
    "        else:\n",
    "            optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = self.get_dataset(dataset_type = 'train', train_size=0.8)\n",
    "        dataloader    = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,num_workers=2)\n",
    "        t_total       = (\n",
    "                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "                // self.hparams.gradient_accumulation_steps\n",
    "                * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = self.get_dataset(dataset_type = 'test', train_size=0.8)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=2)\n",
    "    \n",
    "    def get_dataset(self, dataset_type, train_size=0.8):\n",
    "        df            = pd.read_csv(self.hparams.data_dir)\n",
    "        train_dataset = df.sample(frac=train_size,random_state = self.hparams.seed)\n",
    "        val_dataset   = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "        train_dataset = train_dataset.reset_index(drop=True)\n",
    "        if dataset_type == 'train':\n",
    "            return Dataset(train_dataset, self.tokenizer ,self.hparams.source_length, self.hparams.paraphrase_length)\n",
    "        if dataset_type == 'test':\n",
    "            return Dataset(val_dataset,   self.tokenizer, self.hparams.source_length, self.hparams.paraphrase_length)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022619,
     "end_time": "2022-08-28T15:46:03.184286",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.161667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.244538Z",
     "iopub.status.busy": "2022-08-28T15:46:03.243596Z",
     "iopub.status.idle": "2022-08-28T15:46:03.246442Z",
     "shell.execute_reply": "2022-08-28T15:46:03.245995Z"
    },
    "papermill": {
     "duration": 0.03865,
     "end_time": "2022-08-28T15:46:03.246584",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.207934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, source_len  , par_len  , transform=None):\n",
    "        self.data       = dataframe\n",
    "        self.transform  = transform\n",
    "        self.source_len = source_len\n",
    "        self.par_len    = par_len\n",
    "        self.tokenizer  = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def tokenizing(self,txt_list):\n",
    "      tokenized = [self.tokenizer(txt, max_length=90, truncation=True, padding='max_length', return_tensors='pt')['input_ids'] for txt in txt_list]\n",
    "      if len(txt_list) == 1 : tokenized = tokenized[0]\n",
    "      return tokenized\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sentence_id = self.data.iloc[idx, 0]\n",
    "        sentence    = self.data.iloc[idx, 1]\n",
    "        paraphrase  = self.data.iloc[idx, 2]\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([sentence],    max_length= self.source_len, truncation=True,  padding='max_length' ,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([paraphrase],  max_length= self.par_len,    truncation=True,  padding='max_length'  ,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        if self.transform:\n",
    "            sentence = self.transform(sentence)\n",
    "\n",
    "        return {\n",
    "            'source_ids':   source_ids.to(dtype=torch.long), \n",
    "            'source_mask':  source_mask.to(dtype=torch.long), \n",
    "            'target_ids':   target_ids.to(dtype=torch.long),\n",
    "            'target_mask':  target_mask.to(dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023977,
     "end_time": "2022-08-28T15:46:03.294249",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.270272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# logging class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.350507Z",
     "iopub.status.busy": "2022-08-28T15:46:03.349653Z",
     "iopub.status.idle": "2022-08-28T15:46:03.352790Z",
     "shell.execute_reply": "2022-08-28T15:46:03.352340Z"
    },
    "papermill": {
     "duration": 0.035875,
     "end_time": "2022-08-28T15:46:03.352981",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.317106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "        def on_validation_end(self, trainer, pl_module):\n",
    "            logger.info(\"***** Validation results *****\")\n",
    "            if pl_module.is_logger():\n",
    "                  metrics = trainer.callback_metrics\n",
    "                  # Log results\n",
    "                  for key in sorted(metrics):\n",
    "                    if key not in [\"log\", \"progress_bar\"]:\n",
    "                      logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "        def on_test_end(self, trainer, pl_module):\n",
    "            logger.info(\"***** Test results *****\")\n",
    "\n",
    "            if pl_module.is_logger():\n",
    "                metrics = trainer.callback_metrics\n",
    "\n",
    "                  # Log and save results to file\n",
    "                output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "                with open(output_test_results_file, \"w\") as writer:\n",
    "                    for key in sorted(metrics):\n",
    "                          if key not in [\"log\", \"progress_bar\"]:\n",
    "                            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "                            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022794,
     "end_time": "2022-08-28T15:46:03.398840",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.376046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting up Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.450916Z",
     "iopub.status.busy": "2022-08-28T15:46:03.450048Z",
     "iopub.status.idle": "2022-08-28T15:46:03.453113Z",
     "shell.execute_reply": "2022-08-28T15:46:03.452585Z"
    },
    "papermill": {
     "duration": 0.031682,
     "end_time": "2022-08-28T15:46:03.453211",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.421529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"../input/persian-paraphrase-dataset/Chunk_5_official.csv\", # path for data files\n",
    "    output_dir=\"./checkpoints\", # path to save the checkpoints\n",
    "    model_name_or_path='google/mt5-small',\n",
    "    tokenizer_name_or_path='google/mt5-small',\n",
    "    max_seq_length=512,\n",
    "    source_length = 512,\n",
    "    paraphrase_length = 150,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=5,\n",
    "    eval_batch_size=5,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    n_gpu=1,\n",
    "    #early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.499683Z",
     "iopub.status.busy": "2022-08-28T15:46:03.499019Z",
     "iopub.status.idle": "2022-08-28T15:46:03.502193Z",
     "shell.execute_reply": "2022-08-28T15:46:03.502741Z"
    },
    "papermill": {
     "duration": 0.027655,
     "end_time": "2022-08-28T15:46:03.502849",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.475194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': '../input/persian-paraphrase-dataset/Chunk_5_official.csv', 'output_dir': './checkpoints', 'model_name_or_path': 'google/mt5-small', 'tokenizer_name_or_path': 'google/mt5-small', 'max_seq_length': 512, 'source_length': 512, 'paraphrase_length': 150, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 5, 'eval_batch_size': 5, 'num_train_epochs': 2, 'gradient_accumulation_steps': 8, 'n_gpu': 1, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "print(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020554,
     "end_time": "2022-08-28T15:46:03.544614",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.524060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.593530Z",
     "iopub.status.busy": "2022-08-28T15:46:03.592909Z",
     "iopub.status.idle": "2022-08-28T15:46:03.610435Z",
     "shell.execute_reply": "2022-08-28T15:46:03.609969Z"
    },
    "papermill": {
     "duration": 0.045202,
     "end_time": "2022-08-28T15:46:03.610536",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.565334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory /kaggle/working exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    \n",
    "    period =1,filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:03.659011Z",
     "iopub.status.busy": "2022-08-28T15:46:03.658089Z",
     "iopub.status.idle": "2022-08-28T15:46:51.128994Z",
     "shell.execute_reply": "2022-08-28T15:46:51.128046Z"
    },
    "papermill": {
     "duration": 47.497177,
     "end_time": "2022-08-28T15:46:51.129128",
     "exception": false,
     "start_time": "2022-08-28T15:46:03.631951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7096b96193b443b0bfc3cd683c53017e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=553.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d64d4fca484e25a20e635ab23fc180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1200794589.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e300225495da498ebcb03eaf622c8d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4309802.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235331068b744ca2a497ada42f93290a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=99.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb62ebaf2ae54153b80334ed229b0a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=82.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marman_n\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.10<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">skilled-dream-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/arman_n/transformers_ParsParaphraser\" target=\"_blank\">https://wandb.ai/arman_n/transformers_ParsParaphraser</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/arman_n/transformers_ParsParaphraser/runs/36n4hr2o\" target=\"_blank\">https://wandb.ai/arman_n/transformers_ParsParaphraser/runs/36n4hr2o</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20220828_154649-36n4hr2o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "print (\"Initialize model\")\n",
    "model = T5FineTuner(args)\n",
    "\n",
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T15:46:51.188710Z",
     "iopub.status.busy": "2022-08-28T15:46:51.187722Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-08-28T15:46:51.156172",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                        | Params\n",
      "------------------------------------------------------\n",
      "0 | model | MT5ForConditionalGeneration | 300 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09008627cc644803805e2786a566e85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dcd14ef4c041bf97e40c315ce635ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192997351ab242f99d1690ca3be71ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\" Training model\")\n",
    "trainer.fit(model)\n",
    "\n",
    "print (\"training finished\")\n",
    "\n",
    "print (\"Saving model\")\n",
    "model.model.save_pretrained(\"/kaggle/working/result\")\n",
    "\n",
    "print (\"Saved model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-28T15:45:28.347264",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}