{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "parsparaphraser-translate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamArmanNikkhah/ParsParaphraser/blob/main/parsparaphraser_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Dataset Ready ⚓"
      ],
      "metadata": {
        "id": "skL-Mo6Xia-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download The Dataset**"
      ],
      "metadata": {
        "id": "w_lofiss7zXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gdown"
      ],
      "metadata": {
        "id": "17Q6wAP67V4D",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 150_bdU7auDRp0SFvcrPJUwqardySNDYA   # IF an error occured try again!"
      ],
      "metadata": {
        "id": "Y_Y1JvcZ7W94",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./para-nmt-train.csv')  # CAUTION!! :  edit it kaggle"
      ],
      "metadata": {
        "id": "hDZ295Tg79K2",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Dataset**"
      ],
      "metadata": {
        "id": "pY2sc_jB72Jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataframe(df, n):\n",
        "    # Get the number of rows in the Dataframe\n",
        "    rows = df.shape[0]\n",
        "    # Get the number of rows in each part\n",
        "    part_rows = int(rows / n)\n",
        "    # Create a list to store the Dataframes\n",
        "    list_df = []\n",
        "    # Start the loop\n",
        "    for i in range(n):\n",
        "        # Create the start and end rows\n",
        "        start_row = i * part_rows\n",
        "        end_row = (i + 1) * part_rows\n",
        "        # Create the Dataframe\n",
        "        df_part = df.iloc[start_row:end_row]\n",
        "        # Add the Dataframe to the list\n",
        "        list_df.append(df_part)\n",
        "    # Return the list of Dataframes\n",
        "    return list_df"
      ],
      "metadata": {
        "id": "sYp_rmWh757Q",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_df = split_dataframe(df,8)"
      ],
      "metadata": {
        "id": "Swal-vk48pkf",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗You should change this part :\n",
        "\n",
        "**⏩split_num : the split number that you should translate**"
      ],
      "metadata": {
        "id": "-Glv4Ojw8wwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_num = 5               # CAUTION!! :  change it in accordance with the instruction\n",
        "df        = list_df[split_num]"
      ],
      "metadata": {
        "id": "UHNWrVXs95Qy",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translating"
      ],
      "metadata": {
        "id": "YTBlC2jWZs-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "_fsS7k_3Zzi6",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "#translator = Translator()\n",
        "\n",
        "def translate(text):\n",
        "    try:\n",
        "      translator = Translator()\n",
        "      translation = translator.translate(text, dest='fa')\n",
        "    except:\n",
        "        return text\n",
        "    else:\n",
        "        return translation.text"
      ],
      "metadata": {
        "id": "3IsumPBDaBjH",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "\n",
        "def apply_func(df, func=translate):\n",
        "    df.iloc[:,0] = df.iloc[:,0].apply(func)\n",
        "    df.iloc[:,1] = df.iloc[:,1].apply(func)\n",
        "    return df\n",
        "\n",
        "def parallelize_dataframe(df, func):\n",
        "    df_split = np.array_split(df, num_partitions)\n",
        "    pool = mp.Pool(num_cores)\n",
        "    df = pd.concat(pool.map(func, df_split))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return df\n",
        "\n",
        "def chunk_df(df, n):\n",
        "    \"\"\"\n",
        "    Chunk a dataframe into n equal parts.\n",
        "    \"\"\"\n",
        "    return [df.iloc[i::n, :] for i in range(n)]\n",
        "\n",
        "num_partitions = 4              #number of partitions to split dataframe\n",
        "num_cores      = 4              #number of cores on your machine\n",
        "chunk_num      = 1000\n",
        "\n",
        "filename       = \"Translated_\" + str(split_num) + \".csv\"                 # Don't Change IT !!\n",
        "directory      = \"./\"                                                    # Change it if needed and add / at the end\n",
        "\n",
        "print(f\"Translating Process has been started on the chunk number :{split_num}\\n\")\n",
        "for chunk in chunk_df(df, chunk_num):\n",
        "    chunk_translated = parallelize_dataframe(chunk, apply_func)\n",
        "    chunk_translated.to_csv(directory + filename, mode='a')"
      ],
      "metadata": {
        "id": "8xcq-pl9aENI",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}